# LLMPlan ìš´ì˜ ê°€ì´ë“œ

## ğŸš€ ë°°í¬ ê°€ì´ë“œ

### í”„ë¡œë•ì…˜ ë°°í¬

#### 1. Helmì„ í†µí•œ ë°°í¬

```bash
# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace llmplan

# Helm ì°¨íŠ¸ ë°°í¬
helm install llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan \
  --set image.tag=v0.1.0 \
  --set resources.limits.memory=2Gi \
  --set resources.limits.cpu=1000m \
  --set lmstudio.externalName=lmstudio.internal.company.com

# ë°°í¬ ìƒíƒœ í™•ì¸
helm status llmplan -n llmplan
kubectl get pods -n llmplan
```

#### 2. í™˜ê²½ë³„ ì„¤ì •

**ê°œë°œ í™˜ê²½:**

```bash
helm install llmplan-dev oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan-dev --create-namespace \
  --set image.tag=main \
  --set resources.requests.cpu=250m \
  --set resources.requests.memory=256Mi \
  --set env.DEBUG=true
```

**ìŠ¤í…Œì´ì§• í™˜ê²½:**

```bash
helm install llmplan-staging oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan-staging --create-namespace \
  --set image.tag=latest \
  --set replicaCount=2 \
  --set env.DEBUG=false
```

**í”„ë¡œë•ì…˜ í™˜ê²½:**

```bash
helm install llmplan-prod oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan-prod --create-namespace \
  --set image.tag=v0.1.0 \
  --set replicaCount=3 \
  --set autoscaling.enabled=true \
  --set autoscaling.minReplicas=3 \
  --set autoscaling.maxReplicas=20 \
  --set resources.limits.memory=2Gi \
  --set ingress.enabled=true \
  --set ingress.hosts[0].host=llmplan.company.com
```

### ì—…ë°ì´íŠ¸ ë° ë¡¤ë°±

#### ì—…ë°ì´íŠ¸

```bash
# ìƒˆ ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸
helm upgrade llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan \
  --set image.tag=v0.1.1

# ì„¤ì •ë§Œ ë³€ê²½
helm upgrade llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan \
  --reuse-values \
  --set resources.limits.memory=4Gi
```

#### ë¡¤ë°±

```bash
# ì´ì „ ë²„ì „ìœ¼ë¡œ ë¡¤ë°±
helm rollback llmplan 1 -n llmplan

# ë¡¤ë°± íˆìŠ¤í† ë¦¬ í™•ì¸
helm history llmplan -n llmplan
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### í—¬ìŠ¤ì²´í¬

#### ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

```bash
# Kubernetes ë‚´ë¶€ì—ì„œ
kubectl exec -it deployment/llmplan -n llmplan -- \
  curl http://localhost:8000/api/v1/summary/health

# ì™¸ë¶€ì—ì„œ (í¬íŠ¸ í¬ì›Œë”©)
kubectl port-forward svc/llmplan 8000:8000 -n llmplan
curl http://localhost:8000/api/v1/summary/health
```

#### ì˜ˆìƒ ì‘ë‹µ

```json
// ì •ìƒ
{
  "status": "healthy",
  "service_name": "Text Summarization Service",
  "timestamp": "2025-01-01T00:00:00Z",
  "details": "All systems operational"
}

// ë¹„ì •ìƒ (LMStudio ì—°ê²° ì‹¤íŒ¨)
{
  "status": "unhealthy",
  "service_name": "Text Summarization Service",
  "timestamp": "2025-01-01T00:00:00Z",
  "details": "LMStudio service is not responding"
}
```

### ë¡œê·¸ ëª¨ë‹ˆí„°ë§

#### ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸
kubectl logs -f deployment/llmplan -n llmplan

# ìµœê·¼ 100ì¤„
kubectl logs --tail=100 deployment/llmplan -n llmplan

# ì—ëŸ¬ ë¡œê·¸ë§Œ í•„í„°ë§
kubectl logs deployment/llmplan -n llmplan | grep ERROR

# íŠ¹ì • ì‹œê°„ ë²”ìœ„
kubectl logs deployment/llmplan -n llmplan --since=1h
```

#### ë¡œê·¸ ë ˆë²¨ë³„ ì˜ë¯¸

- **INFO**: ì •ìƒì ì¸ ìš”ì•½ ìš”ì²­/ì‘ë‹µ
- **WARNING**: ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨, ì¬ì‹œë„ ë°œìƒ
- **ERROR**: LMStudio ì—°ê²° ì‹¤íŒ¨, ìš”ì•½ ìƒì„± ì‹¤íŒ¨
- **CRITICAL**: ì„œë¹„ìŠ¤ ì‹œì‘ ì‹¤íŒ¨, ì„¤ì • ì˜¤ë¥˜

### ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

#### CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

```bash
# Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top pods -n llmplan

# ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top nodes

# ìƒì„¸ ë¦¬ì†ŒìŠ¤ ì •ë³´
kubectl describe pod -l app.kubernetes.io/name=llmplan -n llmplan
```

#### HPA ìƒíƒœ í™•ì¸

```bash
# HPA ìƒíƒœ
kubectl get hpa -n llmplan

# HPA ìƒì„¸ ì •ë³´
kubectl describe hpa llmplan -n llmplan

# ìŠ¤ì¼€ì¼ë§ ì´ë²¤íŠ¸
kubectl get events --field-selector reason=SuccessfulRescale -n llmplan
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. Podê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ

```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -n llmplan

# Pod ì´ë²¤íŠ¸ í™•ì¸
kubectl describe pod <pod-name> -n llmplan

# ì¼ë°˜ì ì¸ ì›ì¸:
# - ì´ë¯¸ì§€ Pull ì‹¤íŒ¨: ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ
# - ë¦¬ì†ŒìŠ¤ ë¶€ì¡±: ë…¸ë“œì— CPU/ë©”ëª¨ë¦¬ ë¶€ì¡±
# - ì„¤ì • ì˜¤ë¥˜: ConfigMap, Secret ëˆ„ë½
```

#### 2. í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ (503 ì—ëŸ¬)

```bash
# LMStudio ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
kubectl get svc lmstudio -n llmplan
kubectl get endpoints lmstudio -n llmplan

# LMStudio ì—°ê²° í…ŒìŠ¤íŠ¸
kubectl exec -it deployment/llmplan -n llmplan -- \
  curl -v http://lmstudio:1234/v1/models

# í•´ê²° ë°©ë²•:
# - LMStudio ì„œë¹„ìŠ¤ ì¬ì‹œì‘
# - ë„¤íŠ¸ì›Œí¬ ì •ì±… í™•ì¸
# - DNS í•´ìƒë„ í™•ì¸
```

#### 3. ì‘ë‹µ ì‹œê°„ì´ ëŠë¦¼

```bash
# ìš”ì•½ API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
time curl -X POST http://localhost:8000/api/v1/summary/ \
  -H "Content-Type: application/json" \
  -d '{"text": "í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸..."}'

# ë³‘ëª© ì§€ì  í™•ì¸:
# - LMStudio ëª¨ë¸ ë¡œë”© ìƒíƒœ
# - ë„¤íŠ¸ì›Œí¬ ì§€ì—°
# - Pod ë¦¬ì†ŒìŠ¤ ì œí•œ
```

#### 4. ë©”ëª¨ë¦¬ ë¶€ì¡± (OOMKilled)

```bash
# Pod ì¬ì‹œì‘ ì´ë²¤íŠ¸ í™•ì¸
kubectl get events --field-selector reason=Killing -n llmplan

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl top pods -n llmplan

# í•´ê²° ë°©ë²•:
helm upgrade llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --reuse-values \
  --set resources.limits.memory=2Gi \
  --set resources.requests.memory=1Gi
```

### ì‘ê¸‰ ìƒí™© ëŒ€ì‘

#### ì„œë¹„ìŠ¤ ì™„ì „ ì¤‘ë‹¨

```bash
# 1. ì¦‰ì‹œ ìŠ¤ì¼€ì¼ ì—…
kubectl scale deployment llmplan --replicas=5 -n llmplan

# 2. ì´ì „ ë²„ì „ìœ¼ë¡œ ê¸´ê¸‰ ë¡¤ë°±
helm rollback llmplan -n llmplan

# 3. íŠ¸ë˜í”½ ìš°íšŒ (Ingress ì„¤ì • ë³€ê²½)
kubectl patch ingress llmplan -n llmplan -p '{"spec":{"rules":[]}}'
```

#### ë¶€ë¶„ì  ì¥ì• 

```bash
# 1. ë¬¸ì œê°€ ìˆëŠ” Podë§Œ ì¬ì‹œì‘
kubectl delete pod <problematic-pod> -n llmplan

# 2. ì„¤ì •ë§Œ ë³€ê²½í•˜ì—¬ ë¹ ë¥¸ ìˆ˜ì •
kubectl patch deployment llmplan -n llmplan -p \
  '{"spec":{"template":{"spec":{"containers":[{"name":"llmplan","env":[{"name":"LMSTUDIO_TIMEOUT","value":"60"}]}]}}}}'
```

## ğŸ”§ ìœ ì§€ë³´ìˆ˜

### ì •ê¸° ì ê²€ (ì£¼ê°„)

#### 1. ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€

```bash
# ì „ì²´ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
kubectl get all -n llmplan
helm status llmplan -n llmplan
kubectl top pods -n llmplan
```

#### 2. ë¡œê·¸ ë¶„ì„

```bash
# ì—ëŸ¬ ë¡œê·¸ í†µê³„
kubectl logs deployment/llmplan -n llmplan --since=168h | \
  grep ERROR | wc -l

# ìš”ì•½ ìš”ì²­ í†µê³„
kubectl logs deployment/llmplan -n llmplan --since=168h | \
  grep "POST /api/v1/summary" | wc -l
```

#### 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ í™•ì¸

```bash
# í‰ê·  ì‘ë‹µ ì‹œê°„ (ë¡œê·¸ ê¸°ë°˜)
kubectl logs deployment/llmplan -n llmplan --since=24h | \
  grep "completed in" | \
  awk '{print $NF}' | \
  awk '{sum+=$1; count++} END {print "Average:", sum/count, "ms"}'
```

### ì •ê¸° ì—…ë°ì´íŠ¸ (ì›”ê°„)

#### 1. ë³´ì•ˆ ì—…ë°ì´íŠ¸

```bash
# ìµœì‹  ì´ë¯¸ì§€ë¡œ ì—…ë°ì´íŠ¸
helm upgrade llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --reuse-values \
  --set image.tag=latest
```

#### 2. ì„¤ì • ìµœì í™”

```bash
# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ì¡°ì •
# CPU ì‚¬ìš©ë¥ ì´ ì§€ì†ì ìœ¼ë¡œ ë‚®ìœ¼ë©´ ìš”ì²­ëŸ‰ ê°ì†Œ
# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìœ¼ë©´ ì œí•œëŸ‰ ì¦ê°€
```

### ë°±ì—… ë° ë³µêµ¬

#### ì„¤ì • ë°±ì—…

```bash
# Helm values ë°±ì—…
helm get values llmplan -n llmplan > llmplan-values-backup.yaml

# Kubernetes ë¦¬ì†ŒìŠ¤ ë°±ì—…
kubectl get all -n llmplan -o yaml > llmplan-k8s-backup.yaml
```

#### ë³µêµ¬

```bash
# Helmìœ¼ë¡œ ë³µêµ¬
helm install llmplan oci://registry-1.docker.io/eunheejo/llmplan \
  --namespace llmplan \
  -f llmplan-values-backup.yaml

# Kubernetes ë¦¬ì†ŒìŠ¤ ë³µêµ¬
kubectl apply -f llmplan-k8s-backup.yaml
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ìŠ¤ì¼€ì¼ë§ ì „ëµ

#### ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (HPA)

```yaml
# values.yaml
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
```

#### ìˆ˜ì§ ìŠ¤ì¼€ì¼ë§ (VPA)

```yaml
# VPA ì„¤ì • (ë³„ë„ ì„¤ì¹˜ í•„ìš”)
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: llmplan-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llmplan
  updatePolicy:
    updateMode: "Auto"
```

### ë¦¬ì†ŒìŠ¤ íŠœë‹

#### CPU ìµœì í™”

- **ìš”ì²­ëŸ‰**: ì‹¤ì œ ì‚¬ìš©ëŸ‰ì˜ 80% ìˆ˜ì¤€
- **ì œí•œëŸ‰**: ìš”ì²­ëŸ‰ì˜ 2ë°° ì´í•˜
- **ìŠ¤ì¼€ì¼ë§**: CPU 70% ê¸°ì¤€ìœ¼ë¡œ HPA ì„¤ì •

#### ë©”ëª¨ë¦¬ ìµœì í™”

- **ìš”ì²­ëŸ‰**: ìµœì†Œ í•„ìš”ëŸ‰ + 10% ì—¬ìœ 
- **ì œí•œëŸ‰**: ìš”ì²­ëŸ‰ì˜ 1.5-2ë°°
- **ëª¨ë‹ˆí„°ë§**: OOMKilled ì´ë²¤íŠ¸ ì£¼ì˜ ê¹Šê²Œ ê´€ì°°

### ë„¤íŠ¸ì›Œí¬ ìµœì í™”

#### LMStudio ì—°ê²° ìµœì í™”

```yaml
# values.yaml
env:
  LMSTUDIO_TIMEOUT: "30" # ì‘ë‹µ ëŒ€ê¸° ì‹œê°„
  LMSTUDIO_MAX_RETRIES: "3" # ì¬ì‹œë„ íšŸìˆ˜
```

#### ì„œë¹„ìŠ¤ ë©”ì‹œ (í–¥í›„)

- Istio/Linkerdë¥¼ í†µí•œ íŠ¸ë˜í”½ ê´€ë¦¬
- íšŒë¡œ ì°¨ë‹¨ê¸° íŒ¨í„´
- ë¶€í•˜ ë¶„ì‚° ìµœì í™”
